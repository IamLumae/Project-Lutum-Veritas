# Deep Research Pipeline - Komplett Dokumentation

> Stand: 2026-01-27 | Status: IMPLEMENTIERT

---

## Ãœbersicht

Lutum Veritas fÃ¼hrt **echte Deep Research** durch - nicht das oberflÃ¤chliche "ich google mal kurz" anderer Tools.

**USP:** "Real research takes time. We don't hallucinate in milliseconds."

---

## Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERFACE                               â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Query Input â”‚â†’ â”‚ Plan Review  â”‚â†’ â”‚ Deep Research (Live View)  â”‚  â”‚
â”‚  â”‚             â”‚  â”‚ "Los geht's" â”‚  â”‚ - Sources Boxes            â”‚  â”‚
â”‚  â”‚             â”‚  â”‚              â”‚  â”‚ - Point Summaries          â”‚  â”‚
â”‚  â”‚             â”‚  â”‚              â”‚  â”‚ - Terminal Status          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BACKEND ORCHESTRATOR                            â”‚
â”‚                      /research/deep (SSE)                            â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                   PRO RECHERCHE-PUNKT                        â”‚    â”‚
â”‚  â”‚                                                              â”‚    â”‚
â”‚  â”‚  Think â†’ Search â†’ Pick URLs â†’ Scrape â†’ Dossier â†’ Learnings  â”‚    â”‚
â”‚  â”‚    â”‚                                                    â”‚    â”‚    â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Context-Pass (Learnings) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                              â”‚                                       â”‚
â”‚                              â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              FINAL SYNTHESIS (Qwen 235B)                     â”‚    â”‚
â”‚  â”‚         Alle Dossiers â†’ Gesamtdokument (10+ min)            â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Die Pipeline im Detail

### Phase 1: Setup (Steps 1-4)

| Step | Was passiert | Output |
|------|--------------|--------|
| 1 | User Query â†’ LLM | 10 DDG Queries + Session-Titel |
| 2 | DDG Search | URLs + Snippets |
| 3 | LLM liest gescrapte Seiten | RÃ¼ckfragen an User |
| 4 | User-Antworten â†’ LLM | Recherche-Plan (5-10 Punkte) |

**User entscheidet:** "Los geht's" oder "Plan bearbeiten"

---

### Phase 2: Deep Research Loop (Step 5)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DEEP RESEARCH LOOP                                â”‚
â”‚                                                                      â”‚
â”‚  FÃ¼r jeden Punkt im Plan:                                           â”‚
â”‚                                                                      â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ A) THINK (Diversifiziert)                                  â”‚    â”‚
â”‚   â”‚    Input:  user_query + current_point + previous_learnings â”‚    â”‚
â”‚   â”‚    Output: thinking_block + 10 search_queries              â”‚    â”‚
â”‚   â”‚    Kategorien: 2x PrimÃ¤r, 2x Community, 2x Praktisch,      â”‚    â”‚
â”‚   â”‚                2x Kritisch, 2x Aktuell                     â”‚    â”‚
â”‚   â”‚    Model:  gemini-2.5-flash-lite (60s timeout)             â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â–¼                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ B) DDG SEARCH                                               â”‚    â”‚
â”‚   â”‚    10 Queries â†’ DuckDuckGo (ddgs lib) â†’ 20 results/query   â”‚    â”‚
â”‚   â”‚    = max 200 potenzielle URLs                              â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â–¼                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ C) PICK URLS (Diversifiziert)                               â”‚    â”‚
â”‚   â”‚    LLM wÃ¤hlt EXAKT 20 URLs mit Quellen-Mix:                â”‚    â”‚
â”‚   â”‚    6-8x PrimÃ¤r, 4-5x Community, 3-4x Praktisch,            â”‚    â”‚
â”‚   â”‚    2-3x Kritisch, 2-3x Aktuell                             â”‚    â”‚
â”‚   â”‚    + Query-Awareness + Previous Learnings Kontext          â”‚    â”‚
â”‚   â”‚    â†’ SSE Event: "sources" (zeigt Quellen-Box im Chat)      â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â–¼                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ D) SCRAPE URLS (parallel)                                   â”‚    â”‚
â”‚   â”‚    Camoufox holt Content (max 10.000 Zeichen/Seite)        â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â–¼                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ E) DOSSIER ERSTELLEN                                        â”‚    â”‚
â”‚   â”‚    4 Phasen im Prompt:                                     â”‚    â”‚
â”‚   â”‚    1. Wissen generieren (Fakten, ZusammenhÃ¤nge)            â”‚    â”‚
â”‚   â”‚    2. Dossier schreiben (Struktur, Analyse, Quellen)       â”‚    â”‚
â”‚   â”‚    3. Selbst-PrÃ¼fung (Checkliste)                          â”‚    â”‚
â”‚   â”‚    4. Key Learnings (max 1000 Zeichen fÃ¼r Context-Pass)    â”‚    â”‚
â”‚   â”‚    Model: gemini-2.5-flash-lite (120s timeout)             â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â–¼                                           â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ F) SAVE + EMIT                                              â”‚    â”‚
â”‚   â”‚    - Dossier speichern                                     â”‚    â”‚
â”‚   â”‚    - Key Learnings akkumulieren                            â”‚    â”‚
â”‚   â”‚    â†’ SSE Event: "point_complete" (zeigt Summary im Chat)   â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â–¼                                           â”‚
â”‚              NÃ¤chster Punkt (oder â†’ Final Synthesis)                â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### Diversifizierung (Der "Echo-Chamber-Fix")

**Problem:** Ohne Steuerung findet man 15x GitHub und 0x Reddit/Papers.

**LÃ¶sung:** Beide Schritte erzwingen Vielfalt:

**1. Think-Prompt (Query-Erstellung):**
```
10 Queries in 5 Kategorien:
- search 1-2 (PrimÃ¤r): Offizielle Docs, GitHub, Papers
- search 3-4 (Community): Reddit, HN, Foren
- search 5-6 (Praktisch): Tutorials, Guides, Examples
- search 7-8 (Kritisch): Limitations, Alternatives
- search 9-10 (Aktuell): News 2024/2025, Trends
```

**2. Pick-URLs-Prompt (URL-Auswahl):**
```
EXAKT 20 URLs mit Quellen-Mix:
- 6-8x PrimÃ¤r: GitHub, ArXiv, Docs
- 4-5x Community: Reddit, HN, SO
- 3-4x Praktisch: Tutorials, Blogs
- 2-3x Kritisch: Benchmarks, Vergleiche
- 2-3x Aktuell: News, Releases

+ Query-Awareness: Passt Auswahl an Auftragsart an
+ Previous Learnings: Priorisiert NEUE Infos, keine Duplikate
```

---

### Context-Pass (Der "Amnesie-Fix")

**Problem:** Jeder Punkt lÃ¤uft isoliert (Token-Limit). Punkt 3 weiÃŸ nicht was Punkt 1 gefunden hat.

**LÃ¶sung:** Key Learnings (max 1000 Zeichen) werden akkumuliert:

```
Punkt 1: Recherche â†’ Dossier â†’ Key Learnings extrahieren
         â†“
Punkt 2: bekommt Learnings von 1 â†’ "Das weiÃŸt du schon, suche nicht danach"
         â†“
Punkt 3: bekommt Learnings von 1+2 â†’ ...
         â†“
Final:   bekommt ALLE vollstÃ¤ndigen Dossiers
```

**Key Learnings Format:**
```
=== KEY LEARNINGS ===
**Erkenntnisse:**
- Haupterkenntnis 1
- Haupterkenntnis 2
- Haupterkenntnis 3

**Beste Quellen:**
- URL 1 - Warum wertvoll
- URL 2 - Warum wertvoll

**FÃ¼r nÃ¤chste Schritte relevant:**
Ein Satz was nachfolgende Punkte beachten sollten.
=== END LEARNINGS ===
```

---

### Phase 3: Final Synthesis

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FINAL SYNTHESIS                                 â”‚
â”‚                                                                      â”‚
â”‚  Input:                                                             â”‚
â”‚  - user_query (ursprÃ¼ngliche Aufgabe)                               â”‚
â”‚  - research_plan (alle Punkte)                                      â”‚
â”‚  - all_dossiers (vollstÃ¤ndige Dossiers, nicht nur Learnings)        â”‚
â”‚                                                                      â”‚
â”‚  Prompt (3 Phasen):                                                 â”‚
â”‚  1. META-ANALYSE                                                    â”‚
â”‚     - Querverbindungen zwischen Dossiers                            â”‚
â”‚     - WidersprÃ¼che identifizieren                                   â”‚
â”‚     - Ãœbergreifende Muster                                          â”‚
â”‚     - Synthese-Erkenntnisse (was wird erst durch Kombination klar?) â”‚
â”‚                                                                      â”‚
â”‚  2. DOKUMENT SCHREIBEN                                              â”‚
â”‚     - Executive Summary                                             â”‚
â”‚     - Hauptteil (nach THEMEN, nicht nach Dossiers)                  â”‚
â”‚     - Synthese (Querverbindungen, neue Erkenntnisse)                â”‚
â”‚     - Kritische WÃ¼rdigung                                           â”‚
â”‚     - Handlungsempfehlungen                                         â”‚
â”‚     - Quellenverzeichnis (dedupliziert)                             â”‚
â”‚                                                                      â”‚
â”‚  3. QUALITÃ„TSPRÃœFUNG                                                â”‚
â”‚     - Beantwortet ursprÃ¼ngliche Aufgabe?                            â”‚
â”‚     - Echte Synthese oder nur Zusammenfassung?                      â”‚
â”‚     - Redundanzen eliminiert?                                       â”‚
â”‚     - Min. 3000 WÃ¶rter?                                             â”‚
â”‚                                                                      â”‚
â”‚  Model:   qwen/qwen3-vl-235b-a22b-instruct                          â”‚
â”‚  Timeout: 600 Sekunden (10 Minuten!)                                â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## SSE Events (Backend â†’ Frontend)

| Event Type | Payload | UI Aktion |
|------------|---------|-----------|
| `status` | `{message: "..."}` | Terminal-Status aktualisieren |
| `sources` | `{urls: [...], message: "..."}` | Quellen-Box hinzufÃ¼gen |
| `point_complete` | `{point_title, point_number, total_points, key_learnings}` | Point-Summary-Box hinzufÃ¼gen |
| `done` | `{final_document, total_points, total_sources, duration_seconds}` | Finales Dokument anzeigen |
| `error` | `{message: "..."}` | Fehlermeldung |

---

## UI Komponenten

### 1. Terminal-Status (wÃ¤hrend Recherche lÃ¤uft)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â— â— â—  deep-research                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âš™ $ [2/5] Durchsuche Google... â–‹       â”‚
â”‚ â— â— â— Verarbeite Daten...               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. Sources Box (aufklappbar)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“š Genutzte Quellen (8)              â–¼  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ”— github.com                           â”‚
â”‚    https://github.com/example/repo      â”‚
â”‚ ğŸ”— arxiv.org                            â”‚
â”‚    https://arxiv.org/abs/2024.xxxxx     â”‚
â”‚ ...                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. Point Summary Box (nach jedem Punkt)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ“ Punkt 2/5 abgeschlossen        40%   â”‚
â”‚ â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RAG Architekturen und Best Practices    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ **Erkenntnisse:**                       â”‚
â”‚ - Modular RAG Ã¼bertrifft Naive RAG     â”‚
â”‚ - Hybrid Search (BM25 + Dense) optimal â”‚
â”‚ - Re-Ranking essentiell fÃ¼r PrÃ¤zision  â”‚
â”‚                                         â”‚
â”‚ **Beste Quellen:**                      â”‚
â”‚ - arxiv.org - Comprehensive RAG Survey  â”‚
â”‚ - github.com - llamaindex examples      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Modell-Konfiguration

| Prompt | Modell | Timeout | Zweck |
|--------|--------|---------|-------|
| Think | gemini-2.5-flash-lite | 60s | Suchstrategie entwickeln |
| Pick URLs | gemini-2.5-flash-lite | 60s | Beste URLs auswÃ¤hlen |
| Dossier | gemini-2.5-flash-lite | 120s | Punkt-Dossier erstellen |
| **Final Synthesis** | qwen/qwen3-vl-235b-a22b-instruct | **600s** | Gesamtdokument |

**Warum zwei Modelle?**
- **Flash Lite:** Schnell, gÃ¼nstig, gut fÃ¼r strukturierte Tasks
- **Qwen 235B:** Riesiger Context (alle Dossiers), maximale QualitÃ¤t fÃ¼r Final

---

## Dateien

```
lutum/researcher/prompts/
â”œâ”€â”€ __init__.py          # Exports
â”œâ”€â”€ think.py             # Suchstrategie (+ previous_learnings)
â”œâ”€â”€ pick_urls.py         # URL-Auswahl
â”œâ”€â”€ dossier.py           # Dossier + Key Learnings Parser
â””â”€â”€ final_synthesis.py   # Finale Synthese (Qwen, 600s)

lutum-backend/routes/
â””â”€â”€ research.py          # /research/deep Orchestrator

lutum-desktop/src/
â”œâ”€â”€ stores/sessions.ts   # Message Types (point_summary)
â”œâ”€â”€ hooks/useBackend.ts  # runDeepResearch()
â””â”€â”€ components/
    â”œâ”€â”€ Chat.tsx         # handleStartResearch()
    â””â”€â”€ MessageList.tsx  # PointSummaryBox, Terminal-Status
```

---

## Kosten & Zeit SchÃ¤tzung

| Modus | Dauer | API-Kosten | Output |
|-------|-------|------------|--------|
| Standard (5 Punkte) | 5-15 min | ~$0.50-1.00 | Detaillierter Bericht |
| Umfangreich (10 Punkte) | 15-30 min | ~$1.00-3.00 | Fachbuch-Niveau |

---

## Retry-Loop (Sackgassen-Handler)

Wenn bei einem Punkt weniger als 2 URLs gefunden werden:

```
1. Erkennung: len(selected_urls) < 2
2. Reformulierung: LLM generiert 5 alternative Suchanfragen
   - Andere Keywords
   - Andere Perspektiven (tutorial statt docs)
   - Spezifischer oder allgemeiner
3. Retry: Neue Suchen ausfÃ¼hren
4. Merge: Neue Results zu den alten hinzufÃ¼gen
5. Pick URLs nochmal mit erweitertem Pool
```

Verhindert leere Dossiers bei schwierigen Recherche-Punkten.

---

## NÃ¤chste Schritte (TODO)

- [x] ~~Retry-Loop bei Sackgassen~~ âœ“ Implementiert
- [ ] Modus-Auswahl UI (Standard vs. Akademisch)
- [ ] Export-Funktionen (PDF, Markdown)
- [ ] Akademischer Modus (rekursive Tiefe pro Punkt)
- [ ] Progress-Persistence (Recherche nach Browser-Restart fortsetzen)

---

*Erstellt: 2026-01-27*
*Letztes Update: 2026-01-27 - DDG Search, 10 diversifizierte Queries, 20 diversifizierte URLs/Pick*
